{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bbe7aa",
   "metadata": {},
   "source": [
    "# Use mem0 as a memory store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECURITY FIX: Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load API keys from environment variables\n",
    "import os\n",
    "MEM0_API_KEY = os.getenv('MEM0_API_KEY')\n",
    "if not MEM0_API_KEY:\n",
    "    print(\"WARNING: MEM0_API_KEY not found in environment variables\")\n",
    "    print(\"Please set MEM0_API_KEY in your .env file\")\n",
    "    print(\"The hardcoded API key in this notebook has been removed for security\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4998cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.memory import MemoryContent, MemoryMimeType\n",
    "from autogen_ext.memory.mem0 import Mem0Memory\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba2c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    mem0_memory = Mem0Memory(\n",
    "        user_id='user12345',\n",
    "        is_cloud=True,\n",
    "        api_key=os.getenv('MEM0_API_KEY'))\n",
    "    \n",
    "    try:\n",
    "\n",
    "        print(\"Attempting to add memories to cloud\")\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":'user',\"content\": \"I am a vegetarian food and I love cooking.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":'assistant',\"content\": \"I will remember that preference is Vegetarian.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        mem0_memory._client.add(messages,user_id='user12345',metadata={\"category\": \"preferences\",\"type\": \"diet\"})\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":'user',\"content\": \"I prefer weather information in metric units.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":'assistant',\"content\": \"I will remember that  you prefer metric unit in weather.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        mem0_memory._client.add(messages,user_id='user12345',metadata={\"category\": \"preferences\",\"type\": \"units\"})\n",
    "\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":'user',\"content\": \"My Favourite color is Black.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":'assistant',\"content\": \"I will remember favorite color is black.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        mem0_memory._client.add(messages,user_id='user12345',metadata={\"category\": \"preferences\",\"type\": \"food\"})\n",
    "\n",
    "\n",
    "        print(\"Memories added successfully\")\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding memories: {e}\")\n",
    "\n",
    "    agent = AssistantAgent(\n",
    "        name='assistant',\n",
    "        model_client=model_client,\n",
    "        memory=[mem0_memory],\n",
    "        system_message=\"You are a helpful assistant that remembers user preferences and use them to provide personalized responses.\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = await agent.run(task='What type of food I like ?')\n",
    "\n",
    "        print('Agent Response:',result.messages[-1].content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error running agent: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75239ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to add memories to cloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayank/Github Repos/Live-Class/Agentic 2.0/Autogen/.venv/lib/python3.12/site-packages/mem0/client/utils.py:18: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memories added successfully\n",
      "Agent Response: Based on what I remember, you are a vegetarian and you love cooking. Do you have any specific dishes or cuisines you enjoy most as a vegetarian?\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c04de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresult\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    mem0_memory = Mem0Memory(\n",
    "        user_id='user12345',\n",
    "        is_cloud=True,\n",
    "        api_key=os.getenv('MEM0_API_KEY'))\n",
    "    \n",
    "    try:\n",
    "\n",
    "        print(\"Attempting to add memories to cloud\")\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":'user',\"content\": \"I am a vegetarian food and I love cooking.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":'assistant',\"content\": \"I will remember that preference is Vegetarian.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        mem0_memory._client.add(messages,user_id='user12345',metadata={\"category\": \"preferences\",\"type\": \"diet\"})\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":'user',\"content\": \"I prefer weather information in metric units.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":'assistant',\"content\": \"I will remember that  you prefer metric unit in weather.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        mem0_memory._client.add(messages,user_id='user12345',metadata={\"category\": \"preferences\",\"type\": \"units\"})\n",
    "\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":'user',\"content\": \"My Favourite color is Black.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\":'assistant',\"content\": \"I will remember favorite color is black.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        mem0_memory._client.add(messages,user_id='user12345',metadata={\"category\": \"preferences\",\"type\": \"food\"})\n",
    "\n",
    "\n",
    "        print(\"Memories added successfully\")\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding memories: {e}\")\n",
    "\n",
    "    agent = AssistantAgent(\n",
    "        name='assistant',\n",
    "        model_client=model_client,\n",
    "        memory=[mem0_memory],\n",
    "        system_message=\"You are a helpful assistant that remembers user preferences and use them to provide personalized responses.\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = await agent.run(task='What type of food I like ?')\n",
    "\n",
    "        print('Agent Response:',result.messages[-1].content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error running agent: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a48d14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 °F and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 °C and Sunny.\"\n",
    "    else:\n",
    "        return f\"Sorry, I don't know the weather in {city}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf6c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What are my dietary preferences?\n",
      "---------- MemoryQueryEvent (assistant_agent) ----------\n",
      "[MemoryContent(content='Meal recipe must be vegan', mime_type='text/plain', metadata={'type': 'dietary', 'category': 'preferences', 'score': 0.4950689224919358, 'created_at': datetime.datetime(2025, 8, 1, 20, 42, 30, 215774, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'updated_at': datetime.datetime(2025, 8, 1, 20, 42, 52, 876999, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'categories': ['food', 'user_preferences']}), MemoryContent(content='User prefers weather information in metric units', mime_type='text/plain', metadata={'type': 'units', 'category': 'preferences', 'score': 0.41012687713285934, 'created_at': datetime.datetime(2025, 8, 1, 20, 42, 22, 913275, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'updated_at': datetime.datetime(2025, 8, 1, 20, 42, 22, 933719, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'categories': ['user_preferences', 'misc']})]\n",
      "---------- TextMessage (assistant_agent) ----------\n",
      "Your dietary preference is vegan. If there's anything else you'd like to know or update, feel free to let me know!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='3b9ab2a1-7b8b-48db-9461-2c08bf32acad', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 2, 3, 42, 54, 31582, tzinfo=datetime.timezone.utc), content='What are my dietary preferences?', type='TextMessage'), MemoryQueryEvent(id='5ad77466-453d-4d17-b18a-e49ddf4f0d47', source='assistant_agent', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 2, 3, 42, 54, 335618, tzinfo=datetime.timezone.utc), content=[MemoryContent(content='Meal recipe must be vegan', mime_type='text/plain', metadata={'type': 'dietary', 'category': 'preferences', 'score': 0.4950689224919358, 'created_at': datetime.datetime(2025, 8, 1, 20, 42, 30, 215774, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'updated_at': datetime.datetime(2025, 8, 1, 20, 42, 52, 876999, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'categories': ['food', 'user_preferences']}), MemoryContent(content='User prefers weather information in metric units', mime_type='text/plain', metadata={'type': 'units', 'category': 'preferences', 'score': 0.41012687713285934, 'created_at': datetime.datetime(2025, 8, 1, 20, 42, 22, 913275, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'updated_at': datetime.datetime(2025, 8, 1, 20, 42, 22, 933719, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=61200))), 'categories': ['user_preferences', 'misc']})], type='MemoryQueryEvent'), TextMessage(id='62c6aa68-1eb9-4a80-9e10-694bdac8c4c6', source='assistant_agent', models_usage=RequestUsage(prompt_tokens=115, completion_tokens=25), metadata={}, created_at=datetime.datetime(2025, 8, 2, 3, 42, 55, 647397, tzinfo=datetime.timezone.utc), content=\"Your dietary preference is vegan. If there's anything else you'd like to know or update, feel free to let me know!\", type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 °F and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 °C and Sunny.\"\n",
    "    else:\n",
    "        return f\"Sorry, I don't know the weather in {city}.\"\n",
    "\n",
    "\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import MemoryContent, MemoryMimeType\n",
    "from autogen_ext.memory.mem0 import Mem0Memory\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize Mem0 cloud memory (requires API key)\n",
    "# For local deployment, use is_cloud=False with appropriate config\n",
    "mem0_memory = Mem0Memory(\n",
    "    is_cloud=True,\n",
    "    limit=5,  # Maximum number of memories to retrieve\n",
    "    api_key=os.getenv('MEM0_API_KEY'),\n",
    "    user_id='mayank123'\n",
    ")\n",
    "\n",
    "# Add user preferences to memory\n",
    "await mem0_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"The weather should be in metric units\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "        metadata={\"category\": \"preferences\", \"type\": \"units\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "await mem0_memory.add(\n",
    "    MemoryContent(\n",
    "        content=\"Meal recipe must be vegan\",\n",
    "        mime_type=MemoryMimeType.TEXT,\n",
    "        metadata={\"category\": \"preferences\", \"type\": \"dietary\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create assistant with mem0 memory\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        api_key=api_key\n",
    "    ),\n",
    "    tools=[get_weather],\n",
    "    memory=[mem0_memory],\n",
    ")\n",
    "\n",
    "# Ask about the weather\n",
    "stream = assistant_agent.run_stream(task=\"What are my dietary preferences?\")\n",
    "await Console(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139a2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "from autogen_core.memory import Memory, MemoryContent, MemoryMimeType\n",
    "\n",
    "\n",
    "class SimpleDocumentIndexer:\n",
    "    \"\"\"Basic document indexer for AutoGen Memory.\"\"\"\n",
    "\n",
    "    def __init__(self, memory: Memory, chunk_size: int = 1500) -> None:\n",
    "        self.memory = memory\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    async def _fetch_content(self, source: str) -> str:\n",
    "        \"\"\"Fetch content from URL or file.\"\"\"\n",
    "        if source.startswith((\"http://\", \"https://\")):\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.get(source) as response:\n",
    "                    return await response.text()\n",
    "        else:\n",
    "            async with aiofiles.open(source, \"r\", encoding=\"utf-8\") as f:\n",
    "                return await f.read()\n",
    "\n",
    "    def _strip_html(self, text: str) -> str:\n",
    "        \"\"\"Remove HTML tags and normalize whitespace.\"\"\"\n",
    "        text = re.sub(r\"<[^>]*>\", \" \", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        return text.strip()\n",
    "\n",
    "    def _split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Split text into fixed-size chunks.\"\"\"\n",
    "        chunks: list[str] = []\n",
    "        # Just split text into fixed-size chunks\n",
    "        for i in range(0, len(text), self.chunk_size):\n",
    "            chunk = text[i : i + self.chunk_size]\n",
    "            chunks.append(chunk.strip())\n",
    "        return chunks\n",
    "\n",
    "    async def index_documents(self, sources: List[str]) -> int:\n",
    "        \"\"\"Index documents into memory.\"\"\"\n",
    "        total_chunks = 0\n",
    "\n",
    "        for source in sources:\n",
    "            try:\n",
    "                content = await self._fetch_content(source)\n",
    "\n",
    "                # Strip HTML if content appears to be HTML\n",
    "                if \"<\" in content and \">\" in content:\n",
    "                    content = self._strip_html(content)\n",
    "\n",
    "                chunks = self._split_text(content)\n",
    "\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    await self.memory.add(\n",
    "                        MemoryContent(\n",
    "                            content=chunk, mime_type=MemoryMimeType.TEXT, metadata={\"source\": source, \"chunk_index\": i}\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                total_chunks += len(chunks)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error indexing {source}: {str(e)}\")\n",
    "\n",
    "        return total_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9809aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.memory.chromadb import ChromaDBVectorMemory, PersistentChromaDBVectorMemoryConfig\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize vector memory\n",
    "\n",
    "rag_memory = ChromaDBVectorMemory(\n",
    "    config=PersistentChromaDBVectorMemoryConfig(\n",
    "        collection_name=\"autogen_docs\",\n",
    "        persistence_path=os.path.join(str(Path.home()), \".chromadb_autogen\"),\n",
    "        k=3,  # Return top 3 results\n",
    "        score_threshold=0.4,  # Minimum similarity score\n",
    "    )\n",
    ")\n",
    "\n",
    "await rag_memory.clear()  # Clear existing memory\n",
    "\n",
    "\n",
    "# Index AutoGen documentation\n",
    "async def index_autogen_docs() -> None:\n",
    "    indexer = SimpleDocumentIndexer(memory=rag_memory)\n",
    "    sources = [\n",
    "        \"https://raw.githubusercontent.com/microsoft/autogen/main/README.md\",\n",
    "        \"https://microsoft.github.io/autogen/dev/user-guide/agentchat-user-guide/tutorial/agents.html\",\n",
    "        \"https://microsoft.github.io/autogen/dev/user-guide/agentchat-user-guide/tutorial/teams.html\",\n",
    "        \"https://microsoft.github.io/autogen/dev/user-guide/agentchat-user-guide/tutorial/termination.html\",\n",
    "    ]\n",
    "    chunks: int = await indexer.index_documents(sources)\n",
    "    print(f\"Indexed {chunks} chunks from {len(sources)} AutoGen documents\")\n",
    "\n",
    "\n",
    "await index_autogen_docs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
